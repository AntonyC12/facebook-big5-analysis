# main.py
import time
from src.scraper import FacebookScraper
from src.personality import BigFiveAnalyzer
from src.utils import save_json, format_duration
from config import RAW_DATA_PATH

def main():
    print("ğŸš€ INICIANDO ANÃLISIS DE PERSONALIDAD FACEBOOK")
    print("="*60)
    
    # URL del perfil objetivo (MODIFICA ESTA URL)
    profile_url = "https://facebook.com/tu_perfil_o_amigo"
    
    start_time = time.time()
    
    try:
        # 1. SCRAPING
        print("ğŸ” Fase 1: Scraping de datos...")
        with FacebookScraper(headless=False) as scraper:
            # Asegurar login (manual la primera vez)
            scraper.ensure_login()
            
            # Extraer datos bÃ¡sicos
            basic_info = scraper.scrape_profile_basic_info(profile_url)
            print(f"   ğŸ“‹ Info bÃ¡sica obtenida: {basic_info.get('name', 'No encontrado')}")
            
            # Extraer posts
            posts = scraper.scrape_posts(max_posts=30)
            print(f"   ğŸ“„ {len(posts)} publicaciones obtenidas")
            
            # Simular amigos y grupos (por ahora datos de ejemplo)
            # En un scraper real, implementarÃ­as scrape_friends() y scrape_groups()
            sample_data = {
                "basic_info": basic_info,
                "posts": posts,
                "friends_count": 500,  # Ejemplo
                "groups": ["ProgramaciÃ³n", "MÃºsica", "Deportes"],  # Ejemplo
            }
        
        # Guardar datos crudos
        save_json(sample_data, "facebook_data")
        print("âœ… Scraping completado")
        
        # 2. ANÃLISIS
        print("\nğŸ§  Fase 2: AnÃ¡lisis de personalidad...")
        analyzer = BigFiveAnalyzer()
        
        # Calcular puntuaciones Big Five
        scores = analyzer.calculate_big_five_scores(sample_data)
        
        # Generar reporte
        report = analyzer.generate_personality_report(scores)
        
        print("\n" + "="*60)
        print("ğŸ“Š RESULTADOS BIG FIVE:")
        print("="*60)
        print(report)
        print("="*60)
        
        # Guardar resultados
        save_json(analyzer.results, "big5_results", folder="results")
        
        # 3. ESTADÃSTICAS
        duration = time.time() - start_time
        print(f"\nâ±ï¸  DuraciÃ³n total: {format_duration(duration)}")
        print(f"ğŸ“Š Publicaciones analizadas: {analyzer.results['metadata']['posts_analyzed']}")
        print(f"ğŸ”¤ Palabras analizadas: {analyzer.results['metadata']['words_analyzed']:,}")
        print("\nğŸ‰ AnÃ¡lisis completado exitosamente!")
        
    except KeyboardInterrupt:
        print("\nğŸ›‘ Proceso cancelado por el usuario")
    except Exception as e:
        print(f"\nâŒ Error durante la ejecuciÃ³n: {e}")
        raise

if __name__ == "__main__":
    main()